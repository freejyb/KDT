{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38e05dfe",
   "metadata": {},
   "source": [
    "## LSTM 주가예측하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaff452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://direction-f.tistory.com/23  자료 임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54d428b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM 클래스를 만들어보겠습니다. 여기서는 매 Batch마다 Hidden state와 Cell State를 초기화해주는 Stateless를 적용하겠습니다. \n",
    "# Batch마다 Hidden State와 Cell State를 초기화해줘도 되고 안해줘도 됩니다.\n",
    "# 다만 매번 Batch시에 전에 생성됐던 State를 활용하여 학습하는 것이 이번 미션에서는 적절치 않다고 개인적으로 판단하여 Stateless로 파라미터를 학습하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51548378",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import metrics\n",
    "import datetime\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "os.chdir(\".../new_stock\")\n",
    "from py_stock_data import read_data_from_naver\n",
    "\n",
    "## data input\n",
    "str_datefrom = datetime.datetime.strftime(datetime.datetime(year=2010, month=1, day=1), '%Y.%m.%d')\n",
    "interest_list = [\"096770\"] \n",
    "\n",
    "stock_data ={}\n",
    "\n",
    "for i, code in enumerate(interest_list):\n",
    "    print(i,\":\", code)\n",
    "    new = read_data_from_naver(code)\n",
    "    stock_data[code] = new.read_data(str_datefrom)\n",
    "   \n",
    "\n",
    "data = stock_data[\"096770\"]\n",
    "\n",
    "## data sorting and reset index\n",
    "data=data.sort_values(by=[\"날짜\"], ascending = True).reset_index()\n",
    "data=data.drop([\"index\"], axis=1)\n",
    "\n",
    "## scaling\n",
    "data_ski = data[[\"종가\"]]\n",
    "data_ski.rename(columns={\"종가\": \"Close\"}, inplace = True)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "data_ski[\"Close\"]= scaler.fit_transform(data_ski[\"Close\"].values.reshape(-1,1))\n",
    "\n",
    "## sequence data\n",
    "def make_dataset(data, window_size = 20):\n",
    "    feature_list =[]\n",
    "    label_list =[]\n",
    "    for i in range(len(data)-window_size):\n",
    "        feature_list.append(np.array(data.iloc[i:i+window_size]))\n",
    "        label_list.append(np.array(data.iloc[i+window_size]))\n",
    "        \n",
    "    return np.array(feature_list), np.array(label_list)\n",
    "\n",
    "\n",
    "data_X, data_Y = make_dataset(data_ski)\n",
    "\n",
    "data_X.shape\n",
    "data_Y.shape\n",
    "\n",
    "train_data, train_label = data_X[:-300], data_Y[:-300]\n",
    "test_data, test_label = data_X[-300:], data_Y[-300:]\n",
    "\n",
    "\n",
    "## tensor set\n",
    "X_train = torch.from_numpy(train_data).float()\n",
    "y_train = torch.from_numpy(train_label).float()\n",
    "\n",
    "X_test = torch.from_numpy(test_data).float()\n",
    "y_test = torch.from_numpy(test_label).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d872f68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n",
    "        super(LSTM_, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.input_dim = input_dim\n",
    "        \n",
    "        \n",
    "        self.lstm =nn.LSTM(input_dim, hidden_dim, num_layers, batch_first =True)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0, c0 = self.init_hidden(x)\n",
    "        \n",
    "        out,(hn, cn)=self.lstm(x, (h0,c0))\n",
    "        \n",
    "        \n",
    "        out = self.fc(out[:,-1,:])\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def init_hidden(self,x):\n",
    "        self.h0 =torch.zeros(self.num_layers, x.size(0), self.hidden_dim)\n",
    "        self.c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim)\n",
    "        \n",
    "        return h0, c0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c1d0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Train Loop을 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9be2cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM_(input_dim=1,hidden_dim=30,output_dim=1,num_layers=2)\n",
    "loss_fn = torch.nn.MSELoss(reduction=\"sum\")\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "hist = np.zeros(200)    \n",
    "    \n",
    "for t in range(200):    \n",
    "    \n",
    "    # Forward pass\n",
    "    \n",
    "    y_train_pred = model(X_train)\n",
    "\n",
    "    loss = loss_fn(y_train_pred, y_train)\n",
    "    if t % 10 == 0 and t !=0:\n",
    "        print(\"Epoch \", t, \"MSE: \", loss.item())\n",
    "    hist[t] = loss.item()\n",
    "\n",
    "    # Zero out gradient, else they will accumulate between epochs\n",
    "    optimiser.zero_grad()\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # Update parameters\n",
    "    optimiser.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77394659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train 데이터와 Test 데이터를 활용하여 그래프를 Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c6e6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train Fitting\n",
    "plt.plot(y_train_pred.detach().numpy(), label=\"Preds\")\n",
    "plt.plot(y_train.detach().numpy(), label=\"Real\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "## Test Fitting\n",
    "y_test_pred = model(X_test)\n",
    "plt.plot(y_test_pred.detach().numpy(), label=\"Preds\")\n",
    "plt.plot(y_test.detach().numpy(), label=\"Real\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "## Test Fitting-inverser scaling \n",
    "y_test_pred = scaler.inverse_transform(y_test_pred.detach().numpy())\n",
    "y_test = scaler.inverse_transform(y_test.detach().numpy())\n",
    "plt.plot(y_test_pred,label=\"Preds\")\n",
    "plt.plot(y_test, label = \"Real\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2044832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting이 아닌 예측을 해보도록 하겠습니다. \n",
    "# 구성한 LSTM 모델은 20일치의 데이터를 활용하여 1일치의 데이터를 예측하게 됩니다.\n",
    "\n",
    "# 따라서 처음에는 20일치 데이터를 활용하여 1일치를 예측하고 \n",
    "# 그 다음에는 예측한 값을 우리 데이터인 것처럼 포함하여 예측을 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7048e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seq=X_test[:1] ## X_test에 있는 데이터중 첫번째것을 가지고옮\n",
    "preds =[]\n",
    "\n",
    "for _ in range(len(X_test)):\n",
    "    \n",
    "    # model.init_hidden(test_seq)\n",
    "    y_test_pred = model(test_seq)\n",
    "    \n",
    "    pred = y_test_pred.item()   \n",
    "    preds.append(pred)   \n",
    "    new_seq = test_seq.numpy()    \n",
    "    new_seq = np.append(new_seq, pred)    \n",
    "    new_seq = new_seq[1:] ## index가 0인 것은 제거하여 예측값을 포함하여 20일치 데이터 구성\n",
    "    test_seq = torch.from_numpy(new_seq).view(1,20,1).float()   \n",
    "    \n",
    "plt.plot(preds, label=\"Preds\")\n",
    "plt.plot(y_test.detach().numpy(), label=\"Data\")\n",
    "plt.legend()\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4c39aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
